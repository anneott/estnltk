{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text segmentation\n",
    "## Taggers\n",
    "The following taggers are involved with the text segmentation.\n",
    "### TokensTagger\n",
    "Uses nltk WordPunctTokenizer to tokenize raw text. Creates tokens layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags tokens in raw text.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>TokensTagger</td>\n",
       "      <td>tokens</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apply_punct_postfixes</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "TokensTagger(input_layers=(), output_layer=tokens, output_attributes=(), apply_punct_postfixes=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import TokensTagger\n",
    "tokens_tagger = TokensTagger()\n",
    "tokens_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Aadressilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tuli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kirja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kirjad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spamm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saabus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jooksul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tammsaare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Aadressilt', [{}]),\n",
       "Span('bla', [{}]),\n",
       "Span('@', [{}]),\n",
       "Span('bla', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('ee', [{}]),\n",
       "Span('tuli', [{}]),\n",
       "Span('10', [{}]),\n",
       "Span('000', [{}]),\n",
       "Span('kirja', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('Kirjad', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('st', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('spamm', [{}]),\n",
       "Span('saabus', [{}]),\n",
       "Span('10', [{}]),\n",
       "Span('tunni', [{}]),\n",
       "Span('jooksul', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('A', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('H', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('Tammsaare', [{}]),\n",
       "Span('1935', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('aatal', [{}]),\n",
       "Span(':', [{}]),\n",
       "Span('1', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('0', [{}]),\n",
       "Span('m', [{}]),\n",
       "Span('/', [{}]),\n",
       "Span('s', [{}]),\n",
       "Span('=', [{}]),\n",
       "Span('3', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('67', [{}]),\n",
       "Span('km', [{}]),\n",
       "Span('/', [{}]),\n",
       "Span('h', [{}]),\n",
       "Span('.', [{}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "T = '''Aadressilt bla@bla.ee tuli 10 000 kirja. Kirjad, st. spamm saabus 10 tunni jooksul.\n",
    "\n",
    "A. H. Tammsaare 1935. aatal: 1,0 m / s = 3, 67 km/h.'''\n",
    "text = Text(T)\n",
    "tokens_tagger.tag(text)\n",
    "text['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CompounTokenTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags adjacent tokens that should be analyzed as one word.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>CompoundTokenTagger</td>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>('type', 'normalized')</td>\n",
       "      <td>('tokens',)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>custom_abbreviations</th>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignored_words</th>\n",
       "      <td>set()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_numbers</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_units</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_email_and_www</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_emoticons</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_xml</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_initials</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_abbreviations</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_case_endings</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_hyphenations</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_custom_abbreviations</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do_not_join_on_strings</th>\n",
       "      <td>('\\n\\n',)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "CompoundTokenTagger(input_layers=('tokens',), output_layer=compound_tokens, output_attributes=('type', 'normalized'), custom_abbreviations=(), ignored_words=set(), tag_numbers=True, tag_units=True, tag_email_and_www=True, tag_emoticons=True, tag_xml=True, tag_initials=True, tag_abbreviations=True, tag_case_endings=True, tag_hyphenations=True, use_custom_abbreviations=False, do_not_join_on_strings=('\\n\\n',))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import CompoundTokenTagger\n",
    "compound_token_tagger = CompoundTokenTagger()\n",
    "compound_token_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['bla', '@', 'bla', '.', 'ee']</td>\n",
       "      <td>['email']</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['10', '000']</td>\n",
       "      <td>['numeric']</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['st', '.']</td>\n",
       "      <td>['non_ending_abbreviation']</td>\n",
       "      <td>st.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['A', '.', 'H', '.', 'Tammsaare']</td>\n",
       "      <td>['name_with_initial']</td>\n",
       "      <td>A. H. Tammsaare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['1935', '.']</td>\n",
       "      <td>['numeric']</td>\n",
       "      <td>1935.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['1', ',', '0']</td>\n",
       "      <td>['numeric']</td>\n",
       "      <td>1,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['m', '/', 's']</td>\n",
       "      <td>['unit']</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['km', '/', 'h']</td>\n",
       "      <td>['unit']</td>\n",
       "      <td>km/h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='compound_tokens', attributes=('type', 'normalized'), spans=SL[EnvelopingSpan(['bla', '@', 'bla', '.', 'ee'], [{'type': ['email'], 'normalized': None}]),\n",
       "EnvelopingSpan(['10', '000'], [{'type': ['numeric'], 'normalized': '10000'}]),\n",
       "EnvelopingSpan(['st', '.'], [{'type': ['non_ending_abbreviation'], 'normalized': 'st.'}]),\n",
       "EnvelopingSpan(['A', '.', 'H', '.', 'Tammsaare'], [{'type': ['name_with_initial'], 'normalized': 'A. H. Tammsaare'}]),\n",
       "EnvelopingSpan(['1935', '.'], [{'type': ['numeric'], 'normalized': '1935.'}]),\n",
       "EnvelopingSpan(['1', ',', '0'], [{'type': ['numeric'], 'normalized': '1,0'}]),\n",
       "EnvelopingSpan(['m', '/', 's'], [{'type': ['unit'], 'normalized': 'm/s'}]),\n",
       "EnvelopingSpan(['km', '/', 'h'], [{'type': ['unit'], 'normalized': 'km/h'}])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_token_tagger.tag(text)\n",
    "text['compound_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Creates words layer based on the tokens and compound_tokens layers.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>WordTagger</td>\n",
       "      <td>words</td>\n",
       "      <td>('normalized_form',)</td>\n",
       "      <td>('tokens', 'compound_tokens')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>make_ambiguous</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "WordTagger(input_layers=('tokens', 'compound_tokens'), output_layer=words, output_attributes=('normalized_form',), make_ambiguous=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import WordTagger\n",
    "word_tagger = WordTagger()\n",
    "word_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Aadressilt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bla@bla.ee</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tuli</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10 000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kirja</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kirjad</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>st.</td>\n",
       "      <td>st.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spamm</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saabus</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunni</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jooksul</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A. H. Tammsaare</td>\n",
       "      <td>A. H. Tammsaare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1935.</td>\n",
       "      <td>1935.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aatal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>:</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1,0</td>\n",
       "      <td>1,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m / s</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>=</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>km/h</td>\n",
       "      <td>km/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Aadressilt', [{'normalized_form': None}]),\n",
       "Span('bla@bla.ee', [{'normalized_form': None}]),\n",
       "Span('tuli', [{'normalized_form': None}]),\n",
       "Span('10 000', [{'normalized_form': '10000'}]),\n",
       "Span('kirja', [{'normalized_form': None}]),\n",
       "Span('.', [{'normalized_form': None}]),\n",
       "Span('Kirjad', [{'normalized_form': None}]),\n",
       "Span(',', [{'normalized_form': None}]),\n",
       "Span('st.', [{'normalized_form': 'st.'}]),\n",
       "Span('spamm', [{'normalized_form': None}]),\n",
       "Span('saabus', [{'normalized_form': None}]),\n",
       "Span('10', [{'normalized_form': None}]),\n",
       "Span('tunni', [{'normalized_form': None}]),\n",
       "Span('jooksul', [{'normalized_form': None}]),\n",
       "Span('.', [{'normalized_form': None}]),\n",
       "Span('A. H. Tammsaare', [{'normalized_form': 'A. H. Tammsaare'}]),\n",
       "Span('1935.', [{'normalized_form': '1935.'}]),\n",
       "Span('aatal', [{'normalized_form': None}]),\n",
       "Span(':', [{'normalized_form': None}]),\n",
       "Span('1,0', [{'normalized_form': '1,0'}]),\n",
       "Span('m / s', [{'normalized_form': 'm/s'}]),\n",
       "Span('=', [{'normalized_form': None}]),\n",
       "Span('3', [{'normalized_form': None}]),\n",
       "Span(',', [{'normalized_form': None}]),\n",
       "Span('67', [{'normalized_form': None}]),\n",
       "Span('km/h', [{'normalized_form': 'km/h'}]),\n",
       "Span('.', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tagger.tag(text)\n",
    "text['words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tokenizes text into sentences, and makes sentence tokenization post-corrections where necessary.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>SentenceTokenizer</td>\n",
       "      <td>sentences</td>\n",
       "      <td>()</td>\n",
       "      <td>('words', 'compound_tokens')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_sentence_tokenizer</th>\n",
       "      <td>&lt;nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x0000015C1399D198&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_paragraph_endings</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_compound_tokens</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_numeric</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_parentheses</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_double_quotes</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_inner_title_punct</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_repeated_ending_punct</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_double_quotes_based_on_counts</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_emoticons_as_endings</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_fix_types</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SentenceTokenizer(input_layers=('words', 'compound_tokens'), output_layer=sentences, output_attributes=(), base_sentence_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x0000015C1399D198>, fix_paragraph_endings=True, fix_compound_tokens=True, fix_numeric=True, fix_parentheses=True, fix_double_quotes=True, fix_inner_title_punct=True, fix_repeated_ending_punct=True, fix_double_quotes_based_on_counts=False, use_emoticons_as_endings=True, record_fix_types=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "from estnltk.taggers import SentenceTokenizer\n",
    "sentence_tokenizer = SentenceTokenizer()\n",
    "sentence_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Aadressilt', 'bla@bla.ee', 'tuli', '10 000', 'kirja', '.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Kirjad', ',', 'st.', 'spamm', 'saabus', '10', 'tunni', 'jooksul', '.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['A. H. Tammsaare', '1935.', 'aatal', ':', '1,0', 'm / s', '=', '3', ',', '67', 'km/h', '.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='sentences', attributes=(), spans=SL[EnvelopingSpan(['Aadressilt', 'bla@bla.ee', 'tuli', '10 000', 'kirja', '.'], [{}]),\n",
       "EnvelopingSpan(['Kirjad', ',', 'st.', 'spamm', 'saabus', '10', 'tunni', 'jooksul', '.'], [{}]),\n",
       "EnvelopingSpan(['A. H. Tammsaare', '1935.', 'aatal', ':', '1,0', 'm / s', '=', '3', ',', '67', 'km/h', '.'], [{}])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokenizer.tag(text)\n",
    "text['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = '''Aadressilt bla@bla.ee tuli 10 000 kirja, st. spammi aadressile foo@foo.ee 10 tunni jooksul 2017. aastal. \\\n",
    "A. H. Tammsaare: 1,0 m / s = 3, 67 km/h.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags adjacent sentences that form a paragraph.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ParagraphTokenizer</td>\n",
       "      <td>paragraphs</td>\n",
       "      <td>()</td>\n",
       "      <td>('sentences',)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>regex</th>\n",
       "      <td>\\s*\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paragraph_tokenizer</th>\n",
       "      <td>RegexpTokenizer(pattern='\\\\s*\\n\\n', gaps=True, discard_empty=True, flags=&lt;RegexF ..., type: &lt;class 'nltk.tokenize.regexp.RegexpTokenizer'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ParagraphTokenizer(input_layers=('sentences',), output_layer=paragraphs, output_attributes=(), regex=\\s*\n",
       "\n",
       ", paragraph_tokenizer=RegexpTokenizer(pattern='\\\\s*\\n\\n', gaps=True, discard_empty=True, flags=<RegexF ..., type: <class 'nltk.tokenize.regexp.RegexpTokenizer'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import ParagraphTokenizer\n",
    "paragraph_tokenizer = ParagraphTokenizer()\n",
    "paragraph_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Aadressilt', 'bla@bla.ee', 'tuli', '10 000', 'kirja', '.', 'Kirjad', ',', 'st. ..., type: &lt;class 'list'&gt;, length: 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['A. H. Tammsaare', '1935.', 'aatal', ':', '1,0', 'm / s', '=', '3', ',', '67', 'km/h', '.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='paragraphs', attributes=(), spans=SL[EnvelopingSpan(['Aadressilt', 'bla@bla.ee', 'tuli', '10 000', 'kirja', '.', 'Kirjad', ',', 'st.', 'spamm', 'saabus', '10', 'tunni', 'jooksul', '.'], [{}]),\n",
       "EnvelopingSpan(['A. H. Tammsaare', '1935.', 'aatal', ':', '1,0', 'm / s', '=', '3', ',', '67', 'km/h', '.'], [{}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_tokenizer.tag(text)\n",
    "text['paragraphs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Aadressilt bla@bla.ee tuli 10 000 kirja. Kirjad, st. spamm saabus 10 tunni jooksul.</br></br>A. H. Tammsaare 1935. aatal: 1,0 m / s = 3, 67 km/h.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Aadressilt bla@bla.ee tuli 10 000 kirja. Kirjad, st. spamm saabus 10 tunni jooksul.\\n\\nA. H. Tammsaare 1935. aatal: 1,0 m / s = 3, 67 km/h.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tag_layer\n",
    "All above is equivalent to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Aadressilt bla@bla.ee tuli 10 000 kirja. Kirjad, st. spamm saabus 10 tunni jooksul.</br></br>A. H. Tammsaare 1935. aatal: 1,0 m / s = 3, 67 km/h.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Aadressilt bla@bla.ee tuli 10 000 kirja. Kirjad, st. spamm saabus 10 tunni jooksul.\\n\\nA. H. Tammsaare 1935. aatal: 1,0 m / s = 3, 67 km/h.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text(T).tag_layer(['paragraphs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyse\n",
    "One can also write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Aadressilt bla@bla.ee tuli 10 000 kirja. Kirjad, st. spamm saabus 10 tunni jooksul.</br></br>A. H. Tammsaare 1935. aatal: 1,0 m / s = 3, 67 km/h.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Aadressilt bla@bla.ee tuli 10 000 kirja. Kirjad, st. spamm saabus 10 tunni jooksul.\\n\\nA. H. Tammsaare 1935. aatal: 1,0 m / s = 3, 67 km/h.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text(T).analyse('segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here auxiliary layers are deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aadressilt bla@bla.ee tuli 10 000 kirja, st. spammi aadressile foo@foo.ee 10 tunni jooksul 2017. aastal. A. H. Tammsaare: 1,0 m / s = 3, 67 km/h.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "t = '''Aadressilt bla@bla.ee tuli 10 000 kirja, st. spammi aadressile foo@foo.ee 10 tunni jooksul 2017. aastal. \\\n",
    "A. H. Tammsaare: 1,0 m / s = 3, 67 km/h.'''\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Aadressilt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bla@bla.ee</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tuli</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10 000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kirja</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>st.</td>\n",
       "      <td>st.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spammi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aadressile</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>foo@foo.ee</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunni</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jooksul</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017.</td>\n",
       "      <td>2017.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aastal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A. H. Tammsaare</td>\n",
       "      <td>A. H. Tammsaare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>:</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1,0</td>\n",
       "      <td>1,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m / s</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>=</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>km/h</td>\n",
       "      <td>km/h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Aadressilt', [{'normalized_form': None}]),\n",
       "Span('bla@bla.ee', [{'normalized_form': None}]),\n",
       "Span('tuli', [{'normalized_form': None}]),\n",
       "Span('10 000', [{'normalized_form': '10000'}]),\n",
       "Span('kirja', [{'normalized_form': None}]),\n",
       "Span(',', [{'normalized_form': None}]),\n",
       "Span('st.', [{'normalized_form': 'st.'}]),\n",
       "Span('spammi', [{'normalized_form': None}]),\n",
       "Span('aadressile', [{'normalized_form': None}]),\n",
       "Span('foo@foo.ee', [{'normalized_form': None}]),\n",
       "Span('10', [{'normalized_form': None}]),\n",
       "Span('tunni', [{'normalized_form': None}]),\n",
       "Span('jooksul', [{'normalized_form': None}]),\n",
       "Span('2017.', [{'normalized_form': '2017.'}]),\n",
       "Span('aastal', [{'normalized_form': None}]),\n",
       "Span('.', [{'normalized_form': None}]),\n",
       "Span('A. H. Tammsaare', [{'normalized_form': 'A. H. Tammsaare'}]),\n",
       "Span(':', [{'normalized_form': None}]),\n",
       "Span('1,0', [{'normalized_form': '1,0'}]),\n",
       "Span('m / s', [{'normalized_form': 'm/s'}]),\n",
       "Span('=', [{'normalized_form': None}]),\n",
       "Span('3', [{'normalized_form': None}]),\n",
       "Span(',', [{'normalized_form': None}]),\n",
       "Span('67', [{'normalized_form': None}]),\n",
       "Span('km/h', [{'normalized_form': 'km/h'}]),\n",
       "Span('.', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text(t)\n",
    "text.tag_layer(['words'])\n",
    "text['words']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
