{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering ambiguous morphological analyses\n",
    "\n",
    "By design, Vabamorf's morphological analysis tool is \"agnostic\" on solving all the morphological ambiguities: rather than solving hard cases incorrectly, the tool opts to leave hard ambiguities unresolved, so that the end user can decide how to approach these. \n",
    "As a result, even after applying `VabamorfTagger` or `VabamorfCorpusTagger` with full disambiguation, some of the words still have morphological ambiguities.\n",
    "It is important to note that these ambiguous morphological analyses _are not sorted by probability_, and so, picking the first analysis is not a good strategy on handling these (there is approx 50% chance of getting the correct analysis with that strategy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MorphAnalysisReorderer` reorders ambiguous analyses in a way that the first analysis has a higher likelihood of being the correct one.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, end...</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Üks</td>\n",
       "      <td>Üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ütles</td>\n",
       "      <td>ütles</td>\n",
       "      <td>ütlema</td>\n",
       "      <td>ütle</td>\n",
       "      <td>['ütle']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>['et']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>['1.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tähistab</td>\n",
       "      <td>tähistab</td>\n",
       "      <td>tähistama</td>\n",
       "      <td>tähista</td>\n",
       "      <td>['tähista']</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>['palju']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maid</td>\n",
       "      <td>maid</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>id</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>maid</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töö_rahva_püha</td>\n",
       "      <td>['töö', 'rahva', 'püha']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Üks', [{'normalized_text': 'Üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'N'}, {'normalized_text': 'Üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('ütles', [{'normalized_text': 'ütles', 'lemma': 'ütlema', 'root': 'ütle', 'root_tokens': ['ütle'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('et', [{'normalized_text': 'et', 'lemma': 'et', 'root': 'et', 'root_tokens': ['et'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('1.', [{'normalized_text': '1.', 'lemma': '1.', 'root': '1.', 'root_tokens': ['1.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('mail', [{'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span('tähistab', [{'normalized_text': 'tähistab', 'lemma': 'tähistama', 'root': 'tähista', 'root_tokens': ['tähista'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('palju', [{'normalized_text': 'palju', 'lemma': 'palju', 'root': 'palju', 'root_tokens': ['palju'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('maid', [{'normalized_text': 'maid', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'id', 'clitic': '', 'form': 'pl p', 'partofspeech': 'S'}, {'normalized_text': 'maid', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('töörahvapüha', [{'normalized_text': 'töörahvapüha', 'lemma': 'töörahvapüha', 'root': 'töö_rahva_püha', 'root_tokens': ['töö', 'rahva', 'püha'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Create a text with hard-to-solve ambiguities\n",
    "text=Text(\"Üks ütles, et 1. mail tähistab palju maid töörahvapüha.\")\n",
    "# Tag morph analysis\n",
    "text.tag_layer(['morph_analysis'])\n",
    "\n",
    "# Examine remaining ambiguities\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `MorphAnalysisReorderer` (a `Retagger` of `morph_analysis` layer) to reorder morphological ambiguities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Üks</td>\n",
       "      <td>Üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ütles</td>\n",
       "      <td>ütles</td>\n",
       "      <td>ütlema</td>\n",
       "      <td>ütle</td>\n",
       "      <td>['ütle']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>['et']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>['1.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tähistab</td>\n",
       "      <td>tähistab</td>\n",
       "      <td>tähistama</td>\n",
       "      <td>tähista</td>\n",
       "      <td>['tähista']</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>['palju']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maid</td>\n",
       "      <td>maid</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>id</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>maid</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töö_rahva_püha</td>\n",
       "      <td>['töö', 'rahva', 'püha']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Üks', [{'normalized_text': 'Üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}, {'normalized_text': 'Üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'N'}]),\n",
       "Span('ütles', [{'normalized_text': 'ütles', 'lemma': 'ütlema', 'root': 'ütle', 'root_tokens': ['ütle'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('et', [{'normalized_text': 'et', 'lemma': 'et', 'root': 'et', 'root_tokens': ['et'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('1.', [{'normalized_text': '1.', 'lemma': '1.', 'root': '1.', 'root_tokens': ['1.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('mail', [{'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}]),\n",
       "Span('tähistab', [{'normalized_text': 'tähistab', 'lemma': 'tähistama', 'root': 'tähista', 'root_tokens': ['tähista'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('palju', [{'normalized_text': 'palju', 'lemma': 'palju', 'root': 'palju', 'root_tokens': ['palju'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('maid', [{'normalized_text': 'maid', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'id', 'clitic': '', 'form': 'pl p', 'partofspeech': 'S'}, {'normalized_text': 'maid', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('töörahvapüha', [{'normalized_text': 'töörahvapüha', 'lemma': 'töörahvapüha', 'root': 'töö_rahva_püha', 'root_tokens': ['töö', 'rahva', 'püha'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import MorphAnalysisReorderer\n",
    "\n",
    "morph_reorderer = MorphAnalysisReorderer()\n",
    "morph_reorderer.retag( text )\n",
    "\n",
    "# Examine the order of ambiguities\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the improvements on analysis order of words _üks_ and _mail_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reordering analyses, `MorphAnalysisReorderer` uses a simple frequency-dictionary based approach.\n",
    "\n",
    "   * Firsthand reordering: if a word with ambiguous analyses is in the dictionary mapping from words to their frequency-sorted analyses, then word's ambiguous analyses are re-sorted according to the ordering in the dictionary;\n",
    "\n",
    "\n",
    "   * Fallback reordering: if there was no data for the firsthand reordering, then analyses of an ambiguous word are sorted according to part of speech tags frequency information (based on the dictionary of part of speech corpus frequencies);\n",
    "   \n",
    "   \n",
    "The default dictionaries of `MorphAnalysisReorderer` have been acquired from the training part of the [Estonian Dependency Treebank](https://github.com/UniversalDependencies/UD_Estonian-EDT/tree/5eba261d1ed63507a44063a4e05b77b1db5f4aac).\n",
    "Evaluation on the dev and test parts of the corpus showed that after reorderings, the chance of having the first analysis as the correct one increased from ~50% to ~70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to keep in mind:\n",
    "\n",
    "   * You get a full effect of `MorphAnalysisReorderer` only on morphologically disambiguated texts, e.g. applying it after `VabamorfTagger` or `VabamorfCorpusTagger`. If you apply it after `VabamorfAnalyzer` (on ambiguous `morph_analysis` layer), then the reordering performance is likely suboptimal, because the firsthand reordering dictionary contains only information about words that were left ambiguous after morphological disambiguation process.\n",
    "   \n",
    "   \n",
    "   * The firsthand reordering dictionary of `MorphAnalysisReorderer` may not be the most optimal reorderer for texts of your specific domain. If this is the case, then you can make your of own dictionary of reorderings and use it in `MorphAnalysisReorderer`. See below for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a custom dictionary\n",
    "\n",
    "`MorphAnalysisReorderer` loads its firsthand reordering data from a tab-separated-values format CSV file. The first line in the file must be a header specifying (at minimum) the following attributes:\n",
    " * `text` -- word surface form;\n",
    " * `lemma` -- 'lemma' attribute from 'morph_analysis';\n",
    " * `partofspeech` -- 'partofspeech' attribute from 'morph_analysis';\n",
    " * `form` -- 'form' attribute from 'morph_analysis';\n",
    " * `prob` or `freq` -- probability or frequency of the analysis;\n",
    " \n",
    "Other attributes from the `morph_analysis` layer can also be used if higher precision is needed for differentiating analyses. \n",
    "The header is required to determine in which order the data  needs to be loaded from the file. \n",
    "Each line following the header specifies a single analysis for a word. \n",
    "Naturally, a word having multiple analyses should be described on multiple successive lines.\n",
    "Important: we assume that analyses in CSV file are already in the correct order: sorted from most probable to least probable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV file with correct orderings\n",
    "import tempfile\n",
    "fp = tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', suffix='.csv', delete=False)\n",
    "# Add header\n",
    "fp.write( ('\\t'.join(['text','lemma','partofspeech','form','prob'])) + '\\n' )\n",
    "# Add analysis reorderings:\n",
    "# word 'teine'\n",
    "fp.write( ('\\t'.join(['teine','teine','P','sg n','0.75'])) + '\\n' )\n",
    "fp.write( ('\\t'.join(['teine','teine','N','sg n','0.25'])) + '\\n' )\n",
    "# word 'maid'\n",
    "fp.write( ('\\t'.join(['maid','mai','S','sg p','0.8'])) + '\\n' )\n",
    "fp.write( ('\\t'.join(['maid','maa','S','pl p','0.2'])) + '\\n' )\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new reorderer that loads the firsthand dictionary from the CSV file\n",
    "from estnltk.taggers import MorphAnalysisReorderer\n",
    "\n",
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file = fp.name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Teine</td>\n",
       "      <td>Teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jälle</td>\n",
       "      <td>jälle</td>\n",
       "      <td>jälle</td>\n",
       "      <td>jälle</td>\n",
       "      <td>['jälle']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kirus</td>\n",
       "      <td>kirus</td>\n",
       "      <td>kiruma</td>\n",
       "      <td>kiru</td>\n",
       "      <td>['kiru']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>['1.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maid</td>\n",
       "      <td>maid</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>maid</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>id</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Teine', [{'normalized_text': 'Teine', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}, {'normalized_text': 'Teine', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'O'}]),\n",
       "Span('jälle', [{'normalized_text': 'jälle', 'lemma': 'jälle', 'root': 'jälle', 'root_tokens': ['jälle'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('kirus', [{'normalized_text': 'kirus', 'lemma': 'kiruma', 'root': 'kiru', 'root_tokens': ['kiru'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('1.', [{'normalized_text': '1.', 'lemma': '1.', 'root': '1.', 'root_tokens': ['1.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('maid', [{'normalized_text': 'maid', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}, {'normalized_text': 'maid', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'id', 'clitic': '', 'form': 'pl p', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Create a text with hard-to-solve ambiguities\n",
    "text=Text(\"Teine jälle kirus 1. maid.\")\n",
    "# Tag morph analysis\n",
    "text.tag_layer(['morph_analysis'])\n",
    "\n",
    "# Apply reorderer\n",
    "morph_reorderer.retag(text)\n",
    "\n",
    "# Examine remaining ambiguities\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up: remove temporary file\n",
    "import os\n",
    "os.remove(fp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fallback reordering dictionary\n",
    "\n",
    "In addition to customizing the firsthand dictionary, you can also customize the part of speech dictionary that is used for fallback reordering. \n",
    "Simply initialize reorderer with the parameter `postag_freq_csv_file`:\n",
    "\n",
    "```python\n",
    "from estnltk.taggers import MorphAnalysisReorderer\n",
    "morph_reorderer = MorphAnalysisReorderer( postag_freq_csv_file = 'my_postag_freq.csv' )\n",
    "``` \n",
    "By default, assumes that the CSV file is in tab-separated-values format (dialect='excel-tab') and in the encoding 'utf-8'. The first line must be a header specifying column ordering (`partofspeech` and `freq`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
