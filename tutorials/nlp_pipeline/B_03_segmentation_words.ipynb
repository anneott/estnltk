{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> B. Specific details for programmers: how it works</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Text segmentation: Words </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words\n",
    "\n",
    "Words are often considered as the smallest meaningful units of language, especially from the perspective of syntactic or semantic analysis.\n",
    "In order to get words, outputs of the `TokensTagger` and `CompoundTokenTagger` have to be combined. \n",
    "This is done by `WordTagger` and it is quite straightforward: every compound token is a word, and every token that is not a part of a compound token is also a word. The words are tagged on the raw text the same way as the tokens were. It means that the `words` layer does not depend on `tokens` layer or `compound_tokens` layer and so these layers may be deleted after the words are tagged.\n",
    "\n",
    "In the following example, a text object is created, prerequisite layers (`tokens`, `compound_tokens`) are added to it, and then the layer `words` is tagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>See</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>v-vä-väga</td>\n",
       "      <td>väga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>huvitav</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aga</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kas</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka-su-lik</td>\n",
       "      <td>kasulik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?!</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('See', [{'normalized_form': None}]),\n",
       "Span('on', [{'normalized_form': None}]),\n",
       "Span('v-vä-väga', [{'normalized_form': 'väga'}]),\n",
       "Span('huvitav', [{'normalized_form': None}]),\n",
       "Span(',', [{'normalized_form': None}]),\n",
       "Span('aga', [{'normalized_form': None}]),\n",
       "Span('kas', [{'normalized_form': None}]),\n",
       "Span('ka', [{'normalized_form': None}]),\n",
       "Span('ka-su-lik', [{'normalized_form': 'kasulik'}]),\n",
       "Span('?!', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Prepare text: add tokens and compound tokens\n",
    "text = Text('See on v-vä-väga huvitav, aga kas ka ka-su-lik?!')\n",
    "text.tag_layer(['tokens', 'compound_tokens'])\n",
    "\n",
    "# Add words\n",
    "from estnltk.taggers import WordTagger\n",
    "WordTagger().tag(text)\n",
    "text['words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized word forms. Ambiguity of words\n",
    "\n",
    "The `words` layer has an attribute `normalized_form`, which can contain normalized forms of the surface word. \n",
    "By default, this information is taken from the layer `compound_tokens`: if a compound token has the attribute `normalized` filled in, then this information is also carried over to the `normalized_form` of the corresponding word. Otherwise, `normalized_form` remains `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words layer is _ambiguous_: it can hold multiple normalized forms for each word. This is useful in analysing non-standard varieties of Estonian (such as the Internet slang, or texts written in a dialect): all normalized form candidates that you provide for an unknown  word will be analysed by the downstream morphological analyzer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How normalized forms affect morphological analysis.** If a word has `normalized_form` set to `None`, then only its surface form (`text`) will be analysed morphologically. But if `normalized_form` contains one or more alternative forms (strings), all of these alternatives will be processed by the morphological analyser (`VabamorfAnalyzer`), and the surface form (`text`) will be ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example. Let's first change the normalized forms of a word, and introduce new alternative forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Üsna</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hää</td>\n",
       "      <td>hea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>!</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Üsna', [{'normalized_form': None}]),\n",
       "Span('hää', [{'normalized_form': 'hea'}, {'normalized_form': 'head'}]),\n",
       "Span('!', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Annotation\n",
    "text=Text('Üsna hää!')\n",
    "text.tag_layer(['tokens', 'compound_tokens', 'words'])\n",
    "\n",
    "for word in text.words:\n",
    "    if word.text=='hää':\n",
    "        # Change word's annotations\n",
    "        word.clear_annotations()\n",
    "        word.add_annotation( Annotation(word, normalized_form='hea') )\n",
    "        word.add_annotation( Annotation(word, normalized_form='head') )\n",
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `VabamorfAnalyzer` to provide analyses for all variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Üsna</td>\n",
       "      <td>Üsna</td>\n",
       "      <td>üsna</td>\n",
       "      <td>üsna</td>\n",
       "      <td>['üsna']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hää</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>['!']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Üsna', [{'normalized_text': 'Üsna', 'lemma': 'üsna', 'root': 'üsna', 'root_tokens': ['üsna'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('hää', [{'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'A'}, {'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}, {'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'A'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('!', [{'normalized_text': '!', 'lemma': '!', 'root': '!', 'root_tokens': ['!'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import VabamorfAnalyzer\n",
    "vm_analyser = VabamorfAnalyzer()\n",
    "text.tag_layer(['sentences'])\n",
    "vm_analyser.tag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `morph_analysis` layer has as a special attribute `normalized_text` which holds the string value of the `normalized_form` (or the surface form) that was used as a basis on generating the analysis.\n",
    "From the previous example, we can see that the surface word _'hää'_ has both analyses of the word _'hea'_ and the word _'head'_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(!) How normalized forms affect morphological disambiguation.** \n",
    "If all words in text have at most one `normalized_form` (that is: all analyses of a word in the `morph_analysis` layer correspond to analyses of a single normalized form), then `VabamorfDisambiguator` should be able to provide a high quality morphological disambiguation.\n",
    "However, the morphological disambiguation in the context of words having multiple `normalized_form`-s has not been thoroughly tested, and we have a reason to suspect that such settings may lower the quality of disambiguation. \n",
    "So, be careful when adding more than one normalization to a word (check the disambiguation quality!), and if possible, avoid adding multiple normalized word forms if Vabamorf's disambiguation is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
