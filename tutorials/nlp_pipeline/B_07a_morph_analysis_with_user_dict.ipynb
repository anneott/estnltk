{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological analysis with user dictionary\n",
    "\n",
    "If you need to analyse non-standard Estonian texts (such as the Internet language, transcribed spoken language, or written texts heavily influenced by regional dialects), the standard morphological analyser will probably have suboptimal performance. \n",
    "But if the errors are regular enough, you can compose (either manually or semi-automatically) a user dictionary with corrections.\n",
    "You can apply the dictionary to rewrite `'morph_analysis'` layer, so that words with erroneous analyses will have correct analyses from the dictionary.\n",
    "\n",
    "Let's consider an example sentence from the Internet language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_str = \"see onn hädavajalik vajd merel, xhus vxi metsas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to analyse it with the standard morphological analyser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>['see']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>['onn']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>häda_vajalik</td>\n",
       "      <td>['häda', 'vajalik']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>['vajd']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>merel</td>\n",
       "      <td>merel</td>\n",
       "      <td>meri</td>\n",
       "      <td>meri</td>\n",
       "      <td>['meri']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xhus</td>\n",
       "      <td>xhus</td>\n",
       "      <td>xhu</td>\n",
       "      <td>xhu</td>\n",
       "      <td>['xhu']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>['vxi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metsas</td>\n",
       "      <td>metsas</td>\n",
       "      <td>mets</td>\n",
       "      <td>mets</td>\n",
       "      <td>['mets']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('see', [{'normalized_text': 'see', 'lemma': 'see', 'root': 'see', 'root_tokens': ['see'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('onn', [{'normalized_text': 'onn', 'lemma': 'onn', 'root': 'onn', 'root_tokens': ['onn'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('hädavajalik', [{'normalized_text': 'hädavajalik', 'lemma': 'hädavajalik', 'root': 'häda_vajalik', 'root_tokens': ['häda', 'vajalik'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('vajd', [{'normalized_text': 'vajd', 'lemma': 'vajd', 'root': 'vajd', 'root_tokens': ['vajd'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('merel', [{'normalized_text': 'merel', 'lemma': 'meri', 'root': 'meri', 'root_tokens': ['meri'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('xhus', [{'normalized_text': 'xhus', 'lemma': 'xhu', 'root': 'xhu', 'root_tokens': ['xhu'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}]),\n",
       "Span('vxi', [{'normalized_text': 'vxi', 'lemma': 'vxi', 'root': 'vxi', 'root_tokens': ['vxi'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('metsas', [{'normalized_text': 'metsas', 'lemma': 'mets', 'root': 'mets', 'root_tokens': ['mets'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text(text_str)\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the results were not so good.\n",
    "\n",
    "But we can create a dictionary listing correct analyses for each word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_corrections = {\n",
    "    'onn' : [{'normalized_text':'on', 'form': 'b', 'root': 'ole', 'ending':'0', 'partofspeech': 'V', 'clitic':''}], \n",
    "    'vajd': [{'normalized_text':'vaid', 'form': '', 'root': 'vaid', 'ending':'0', 'partofspeech': 'D', 'clitic':''}],\n",
    "    'xhus': [{'normalized_text':'õhus', 'form': 'sg in', 'root': 'õhk', 'ending':'s', 'partofspeech': 'S', 'clitic':''}],\n",
    "    'vxi' : [{'normalized_text':'või', 'form': '', 'root': 'või', 'ending':'0', 'partofspeech': 'J', 'clitic':''}]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and pass the dictionary to `UserDictTagger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import UserDictTagger\n",
    "\n",
    "# Create new user dictionary tagger (stores words in case insensitive manner)\n",
    "userdict = UserDictTagger(words_dict=my_corrections, ignore_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and apply the tagger to correct the analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>['see']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>häda_vajalik</td>\n",
       "      <td>['häda', 'vajalik']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajd</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>['vaid']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>merel</td>\n",
       "      <td>merel</td>\n",
       "      <td>meri</td>\n",
       "      <td>meri</td>\n",
       "      <td>['meri']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xhus</td>\n",
       "      <td>õhus</td>\n",
       "      <td>õhk</td>\n",
       "      <td>õhk</td>\n",
       "      <td>['õhk']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vxi</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>['või']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metsas</td>\n",
       "      <td>metsas</td>\n",
       "      <td>mets</td>\n",
       "      <td>mets</td>\n",
       "      <td>['mets']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('see', [{'normalized_text': 'see', 'lemma': 'see', 'root': 'see', 'root_tokens': ['see'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('onn', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('hädavajalik', [{'normalized_text': 'hädavajalik', 'lemma': 'hädavajalik', 'root': 'häda_vajalik', 'root_tokens': ['häda', 'vajalik'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('vajd', [{'normalized_text': 'vaid', 'lemma': 'vaid', 'root': 'vaid', 'root_tokens': ['vaid'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('merel', [{'normalized_text': 'merel', 'lemma': 'meri', 'root': 'meri', 'root_tokens': ['meri'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('xhus', [{'normalized_text': 'õhus', 'lemma': 'õhk', 'root': 'õhk', 'root_tokens': ['õhk'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}]),\n",
       "Span('vxi', [{'normalized_text': 'või', 'lemma': 'või', 'root': 'või', 'root_tokens': ['või'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('metsas', [{'normalized_text': 'metsas', 'lemma': 'mets', 'root': 'mets', 'root_tokens': ['mets'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Voilà !_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes about `normalized_text`:\n",
    "   * Dictionary's entry for a word may contain `normalized_text` value, but this is not mandatory. Note, however, that if  `normalized_text` is missing from the entry (and you are using complete overwriting), then by default, the value of `normalized_text` will be set to `None`;\n",
    "\n",
    "\n",
    "   * You can initialize `UserDictTagger` with the parameter `replace_missing_normalized_text_with_text=True`. After that, if a `normalized_text` is missing from the dictionary entry, then its value will be replaced with word's text. Note, however, that if word's text is a non-standard word form (such as _vajd_, _xhus_, _vxi_ in the previous example), then the outcome will be misleading (a normalized_text is actually the non-standard one). So, you should use this option only if all word texts in your dictionary correspond to standard / normalized words;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial overwriting\n",
    "\n",
    "If the existing analysis only needs partial corrections (e.g. only the root attribute is incorrect), you can create an entry  that maps a word to a dictionary, which provides corrections only to specific attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrections only for 'root' and 'partofspeech' of the word (leave other attributes as they are)\n",
    "my_corrections = {\n",
    "    'igapäävased': { 'root': 'iga_päevane', 'partofspeech': 'A'} \n",
    "}\n",
    "# Create new user dictionary\n",
    "userdict = UserDictTagger( words_dict=my_corrections )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävask</td>\n",
       "      <td>igapää_vask</td>\n",
       "      <td>['igapää', 'vask']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('igapäävased', [{'normalized_text': 'igapäävased', 'lemma': 'igapäävask', 'root': 'igapää_vask', 'root_tokens': ['igapää', 'vask'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: word thad needs corrections only in the root and partofspeech\n",
    "text = Text('igapäävased')\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäevane</td>\n",
       "      <td>iga_päevane</td>\n",
       "      <td>['iga', 'päevane']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('igapäävased', [{'normalized_text': 'igapäävased', 'lemma': 'igapäevane', 'root': 'iga_päevane', 'root_tokens': ['iga', 'päevane'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections:\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the corrections, existing analyses of the word will then be merged with the new attributes from the dictionary -- attributes present in the user dictionary will be overwritten, and attributes not present in the dictionary will remain as they are.\n",
    "\n",
    "The minimum requirement for the dictionary of partial overwriting: it must specify at least one of the fields: `'root'`, `'ending'`, `'clitic'`, `'form'`, and `'partofspeech'`. Note: if `'root'` is provided, then `'partofspeech'` must also be provided (see below for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overwriting `'root'`, `'lemma'` and `'root_tokens'`\n",
    "\n",
    "Attributes `'root'` and `'lemma'` and `'root_tokens'` all record information about the morphological base form of the word, and its segmentation. \n",
    "If you need to change one of these attributes, you should update all in order to keep the data consistent. \n",
    "There is a systematic way how to do it.\n",
    "You should restrict your dictionary entries only to `'root'` and `'partofspeech'` (and `'ending'`, if required). Attributes `'lemma'` and `'root_tokens'` will then be automatically generated based on `'root'` and `'partofspeech'` (so, no need to manually provide entries for `'lemma'` and `'root_tokens'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new user dictionary with corrections to root and pos\n",
    "my_corrections = {\n",
    "    'abieluettepanek': { 'root': 'abielu_ettepanek', 'partofspeech': 'S' } \n",
    "}\n",
    "userdict = UserDictTagger( words_dict = my_corrections )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abi_elu_ette_panek</td>\n",
       "      <td>['abi', 'elu', 'ette', 'panek']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('abieluettepanek', [{'normalized_text': 'abieluettepanek', 'lemma': 'abieluettepanek', 'root': 'abi_elu_ette_panek', 'root_tokens': ['abi', 'elu', 'ette', 'panek'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: 'abieluettepanek' is a compound word thad needs corrections in the root\n",
    "text = Text('abieluettepanek')\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abielu_ettepanek</td>\n",
       "      <td>['abielu', 'ettepanek']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('abieluettepanek', [{'normalized_text': 'abieluettepanek', 'lemma': 'abieluettepanek', 'root': 'abielu_ettepanek', 'root_tokens': ['abielu', 'ettepanek'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete overwriting\n",
    "\n",
    "If the correction entry maps a word to a list of dictionaries, then all old anayses of the word will be replaced by the listed analyses. \n",
    "A list with a single dictionary means that the word is unambiguous, and multiple dictionaries represent different analysis variants of an ambiguous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new user dictionary with multiple analysis variants\n",
    "my_corrections = {\n",
    "    'onn': [{'form': 'b', 'root': 'ole', 'ending':'0', 'partofspeech': 'V', 'clitic':''},\\\n",
    "            {'form': 'vad', 'root': 'ole', 'ending':'0', 'partofspeech': 'V', 'clitic':''} ]\n",
    "}\n",
    "userdict = UserDictTagger( words_dict = my_corrections )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>['vist']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>['onn']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>['rahul']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('vist', [{'normalized_text': 'vist', 'lemma': 'vist', 'root': 'vist', 'root_tokens': ['vist'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('onn', [{'normalized_text': 'onn', 'lemma': 'onn', 'root': 'onn', 'root_tokens': ['onn'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('rahul', [{'normalized_text': 'rahul', 'lemma': 'rahul', 'root': 'rahul', 'root_tokens': ['rahul'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: verb needs corrections, but the ambiguities should remain\n",
    "#          ( because it is not clear from the context, which form is correct )\n",
    "text = Text('vist onn rahul')\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>['vist']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>None</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>['rahul']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('vist', [{'normalized_text': 'vist', 'lemma': 'vist', 'root': 'vist', 'root_tokens': ['vist'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('onn', [{'normalized_text': None, 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': None, 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('rahul', [{'normalized_text': 'rahul', 'lemma': 'rahul', 'root': 'rahul', 'root_tokens': ['rahul'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum requirement for the dictionary used in complete overwriting: it must specify all the fields `'root'`, `'ending'`, `'clitic'`, `'form'`, and `'partofspeech'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some details\n",
    "\n",
    "#### About dictionary lookup\n",
    "\n",
    "Words that you add to `UserDictTagger` will be matched against `normalized_text` values of text's morphological analyses. \n",
    "If a morphological analysis has `normalized_text` equal to `None`, then the dictionary word will be matched against `text` of the morphological analysis. By default, the matching is case sensitive, but you can turn it off by setting `ignore_case=True` when initializing `UserDictTagger`.\n",
    "\n",
    "#### About matching and matching priorities\n",
    "\n",
    "If a match is found, and `UserDictTagger`'s entry for the word corresponds to a dictionary, then the _partial overwriting strategy_ will be applied: only those morphological analysis' attributes that are in the dictionary will overwritten, and all other attributes remain as they are.\n",
    "If matching word's entry is a list of dictionaries, the _complete overwriting strategy_ will be applied: all morphological analyses of the word will be replaced by analyses from the corresponding `UserDictTagger`'s entry.\n",
    "\n",
    "If some of word's morphological analyses obtain _partial overwriting_ matches, and some obtain _complete overwriting_ matches, then the final result will be complete overwriting according to the last complete overwriting match.\n",
    "In similar vein, if there is more than one morphological analysis that obtains a complete overwriting match, then the final result will be overwriting according to the last complete overwriting match (so, all matches previous to the last will be ignored).\n",
    "\n",
    "#### How to overwrite only unknown words\n",
    "\n",
    "By default, `UserDictTagger` overwrites all words that can be matched to the user dictionary. This means that unknown words with `None` analyses are overwritten as well as known words with existing analyses.\n",
    "However, you can use the setting `overwrite_existing=False` on initializing `UserDictTagger` to turn off overwriting of existing analyses.\n",
    "With this setting, only words with `None` analyses will obtain analyses from the user dictionary, and all words with existing analyses will remain as they are.\n",
    "\n",
    "#### How to turn off category validation [Advanced]\n",
    "\n",
    "Analyses added to the `UserDictTagger` will be checked for validity of partofspeech and form categories. \n",
    "The validation checks if the respective category values are valid category values for Vabamorf. \n",
    "If you want to introduce new categories, then you can turn off category validation with the flag `validate_vm_categories=False` upon initialization.\n",
    "\n",
    "#### Browsing the content of dictionary\n",
    "\n",
    "You can use tagger's method `save_as_csv( None )` to get the full content of the user dictionary as a CSV formatted string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\troot\tending\tclitic\tform\tpartofspeech\r\n",
      "onn\tole\t0\t\tb\tV\r\n",
      "onn\tole\t0\t\tvad\tV\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "print( userdict.save_as_csv(None) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the section \"Saving analyses to CSV file\" below for details about the method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading analyses from CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of passing analyses to the tagger via parameter `words_dict`, you can use parameter `csv_file` for specifying the name of the CSV from which analyses will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV file with correct analyses\n",
    "import tempfile\n",
    "fp = tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', suffix='.csv', delete=False)\n",
    "# Add header\n",
    "fp.write('text,form,root,ending,partofspeech,clitic\\n')\n",
    "# Add analyses\n",
    "fp.write('mxnel,sg ad,mõni,l,P,\\n')\n",
    "fp.write('igapäävased,pl n,iga_päevane,d,A,\\n')\n",
    "fp.write('kxnekeeleväljändid,pl n,kõne_keele_väljend,d,S,\\n')\n",
    "fp.write('sellged,pl n,selge,d,A,\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is required that the first line of the CSV file is the header, and uses the heading names `'root'`, `'ending'`, `'clitic'`, `'form'`, `'partofspeech'`, `'text'`. This is required to determine in which order the data has to be loaded from the file.\n",
    "\n",
    "Each line following the heading specifies a single analysis for a word. The word itself must be under the column `'text'`. Note that like in case of the _complete overwriting_, all the fields `'root'`, `'ending'`, `'clitic'`, `'form'` and `'partofspeech'` must be specified. You can also provide multiple lines describing a single word: these will be then considered as different analysis variants of an ambiguous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new user dictionary with the analyses loaded from the CSV file\n",
    "userdict = UserDictTagger( csv_file=fp.name, encoding='utf-8', delimiter=',' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can pass optional parameters, such as `dialect` and `delimiter`, to the constructor in order to specify the formatting of the CSV file. Basically, you can use the same parameters as can be used with the method `csv.reader`: https://docs.python.org/3/library/csv.html#csv.reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mxnel</td>\n",
       "      <td>mxnel</td>\n",
       "      <td>mxne</td>\n",
       "      <td>mxne</td>\n",
       "      <td>['mxne']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>['ka']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävask</td>\n",
       "      <td>igapää_vask</td>\n",
       "      <td>['igapää', 'vask']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljänd</td>\n",
       "      <td>kxnekeeleväljänd</td>\n",
       "      <td>['kxnekeeleväljänd']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljändi</td>\n",
       "      <td>kxnekeeleväljändi</td>\n",
       "      <td>['kxnekeeleväljändi']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljänt</td>\n",
       "      <td>kxnekeeleväljänt</td>\n",
       "      <td>['kxnekeeleväljänt']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sellged</td>\n",
       "      <td>sellged</td>\n",
       "      <td>sellge</td>\n",
       "      <td>sellge</td>\n",
       "      <td>['sellge']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>sellged</td>\n",
       "      <td>sellged</td>\n",
       "      <td>sellged</td>\n",
       "      <td>['sellged']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mxnel', [{'normalized_text': 'mxnel', 'lemma': 'mxne', 'root': 'mxne', 'root_tokens': ['mxne'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span('ka', [{'normalized_text': 'ka', 'lemma': 'ka', 'root': 'ka', 'root_tokens': ['ka'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('igapäävased', [{'normalized_text': 'igapäävased', 'lemma': 'igapäävask', 'root': 'igapää_vask', 'root_tokens': ['igapää', 'vask'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('kxnekeeleväljändid', [{'normalized_text': 'kxnekeeleväljändid', 'lemma': 'kxnekeeleväljänd', 'root': 'kxnekeeleväljänd', 'root_tokens': ['kxnekeeleväljänd'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'kxnekeeleväljändid', 'lemma': 'kxnekeeleväljändi', 'root': 'kxnekeeleväljändi', 'root_tokens': ['kxnekeeleväljändi'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'kxnekeeleväljändid', 'lemma': 'kxnekeeleväljänt', 'root': 'kxnekeeleväljänt', 'root_tokens': ['kxnekeeleväljänt'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('sellged', [{'normalized_text': 'sellged', 'lemma': 'sellge', 'root': 'sellge', 'root_tokens': ['sellge'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'sellged', 'lemma': 'sellged', 'root': 'sellged', 'root_tokens': ['sellged'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: a difficult-to-analyse sentence from the Internet language\n",
    "text = Text(\"mxnel ka igapäävased kxnekeeleväljändid sellged\")\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mxnel</td>\n",
       "      <td>None</td>\n",
       "      <td>mõni</td>\n",
       "      <td>mõni</td>\n",
       "      <td>['mõni']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>['ka']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>None</td>\n",
       "      <td>igapäevane</td>\n",
       "      <td>iga_päevane</td>\n",
       "      <td>['iga', 'päevane']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>None</td>\n",
       "      <td>kõnekeeleväljend</td>\n",
       "      <td>kõne_keele_väljend</td>\n",
       "      <td>['kõne', 'keele', 'väljend']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sellged</td>\n",
       "      <td>None</td>\n",
       "      <td>selge</td>\n",
       "      <td>selge</td>\n",
       "      <td>['selge']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mxnel', [{'normalized_text': None, 'lemma': 'mõni', 'root': 'mõni', 'root_tokens': ['mõni'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'P'}]),\n",
       "Span('ka', [{'normalized_text': 'ka', 'lemma': 'ka', 'root': 'ka', 'root_tokens': ['ka'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('igapäävased', [{'normalized_text': None, 'lemma': 'igapäevane', 'root': 'iga_päevane', 'root_tokens': ['iga', 'päevane'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}]),\n",
       "Span('kxnekeeleväljändid', [{'normalized_text': None, 'lemma': 'kõnekeeleväljend', 'root': 'kõne_keele_väljend', 'root_tokens': ['kõne', 'keele', 'väljend'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('sellged', [{'normalized_text': None, 'lemma': 'selge', 'root': 'selge', 'root_tokens': ['selge'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up: remove temporary file\n",
    "import os\n",
    "os.remove(fp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving analyses to CSV file\n",
    "\n",
    "Method `save_as_csv( filename )` can be used for saving the content of the user dictionary to a CSV format file. The data is saved in a way that it can be loaded with the parameter `csv_file`. \n",
    "\n",
    "Note 1: you can also pass optional parameters, such as `dialect` and `delimiter`, to the `save_as_csv( filename )` in order to change the formatting of the CSV. Basically, you can use the same parameters as can be used with the method `csv.writer`: https://docs.python.org/3/library/csv.html#csv.writer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 2: if you use `None` in place of _filename_, then the method constructs and returns a CSV formatted string instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\troot\tending\tclitic\tform\tpartofspeech\r\n",
      "igapäävased\tiga_päevane\td\t\tpl n\tA\r\n",
      "kxnekeeleväljändid\tkõne_keele_väljend\td\t\tpl n\tS\r\n",
      "mxnel\tmõni\tl\t\tsg ad\tP\r\n",
      "sellged\tselge\td\t\tpl n\tA\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "print( userdict.save_as_csv( None ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 3: if the dictionary contains partial overwriting entries, then the output CSV will have `'----------'` in places of attribute values that were not described in the (partial overwriting) dictionary."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
