{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological analysis with user dictionary\n",
    "\n",
    "If you need to analyse non-standard Estonian texts (such as the Internet language, transcribed spoken language, or written texts heavily influenced by regional dialects), the standard morphological analyser will probably have suboptimal performance. \n",
    "But if the errors are regular enough, you can compose (either manually or semi-automatically) a user dictionary with corrections.\n",
    "You can apply the dictionary to rewrite `'morph_analysis'` layer, so that words with erroneous analyses will have correct analyses from the dictionary.\n",
    "\n",
    "Let's consider an example sentence from the Internet language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_str = \"see onn hädavajalik vajd merel, xhus vxi metsas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to analyse it with the standard morphological analyser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>['see']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>['onn']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>häda_vajalik</td>\n",
       "      <td>['häda', 'vajalik']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>['vajd']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>merel</td>\n",
       "      <td>merel</td>\n",
       "      <td>meri</td>\n",
       "      <td>meri</td>\n",
       "      <td>['meri']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xhus</td>\n",
       "      <td>xhus</td>\n",
       "      <td>xhu</td>\n",
       "      <td>xhu</td>\n",
       "      <td>['xhu']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>['vxi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metsas</td>\n",
       "      <td>metsas</td>\n",
       "      <td>mets</td>\n",
       "      <td>mets</td>\n",
       "      <td>['mets']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('see', [{'normalized_text': 'see', 'lemma': 'see', 'root': 'see', 'root_tokens': ['see'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('onn', [{'normalized_text': 'onn', 'lemma': 'onn', 'root': 'onn', 'root_tokens': ['onn'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('hädavajalik', [{'normalized_text': 'hädavajalik', 'lemma': 'hädavajalik', 'root': 'häda_vajalik', 'root_tokens': ['häda', 'vajalik'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('vajd', [{'normalized_text': 'vajd', 'lemma': 'vajd', 'root': 'vajd', 'root_tokens': ['vajd'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('merel', [{'normalized_text': 'merel', 'lemma': 'meri', 'root': 'meri', 'root_tokens': ['meri'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('xhus', [{'normalized_text': 'xhus', 'lemma': 'xhu', 'root': 'xhu', 'root_tokens': ['xhu'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}]),\n",
       "Span('vxi', [{'normalized_text': 'vxi', 'lemma': 'vxi', 'root': 'vxi', 'root_tokens': ['vxi'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('metsas', [{'normalized_text': 'metsas', 'lemma': 'mets', 'root': 'mets', 'root_tokens': ['mets'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text(text_str)\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the results were not so good.\n",
    "\n",
    "But we can create an user dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import UserDictTagger\n",
    "\n",
    "# Create new user dictionary (stores words in case insensitive manner)\n",
    "userdict = UserDictTagger(ignore_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and populate it with correct analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "userdict.add_word('onn', [{'normalized_text':'on', 'form': 'b', 'root': 'ole', 'ending':'0', 'partofspeech': 'V', 'clitic':''}] )\n",
    "userdict.add_word('vajd', [{'normalized_text':'vaid', 'form': '', 'root': 'vaid', 'ending':'0', 'partofspeech': 'D', 'clitic':''}] )\n",
    "userdict.add_word('xhus', [{'normalized_text':'õhus', 'form': 'sg in', 'root': 'õhk', 'ending':'s', 'partofspeech': 'S', 'clitic':''}] )\n",
    "userdict.add_word('vxi', [{'normalized_text':'või', 'form': '', 'root': 'või', 'ending':'0', 'partofspeech': 'J', 'clitic':''}] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and apply it to correct the analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>['see']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>häda_vajalik</td>\n",
       "      <td>['häda', 'vajalik']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajd</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>['vaid']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>merel</td>\n",
       "      <td>merel</td>\n",
       "      <td>meri</td>\n",
       "      <td>meri</td>\n",
       "      <td>['meri']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xhus</td>\n",
       "      <td>õhus</td>\n",
       "      <td>õhk</td>\n",
       "      <td>õhk</td>\n",
       "      <td>['õhk']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vxi</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>['või']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metsas</td>\n",
       "      <td>metsas</td>\n",
       "      <td>mets</td>\n",
       "      <td>mets</td>\n",
       "      <td>['mets']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('see', [{'normalized_text': 'see', 'lemma': 'see', 'root': 'see', 'root_tokens': ['see'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('onn', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('hädavajalik', [{'normalized_text': 'hädavajalik', 'lemma': 'hädavajalik', 'root': 'häda_vajalik', 'root_tokens': ['häda', 'vajalik'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('vajd', [{'normalized_text': 'vaid', 'lemma': 'vaid', 'root': 'vaid', 'root_tokens': ['vaid'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('merel', [{'normalized_text': 'merel', 'lemma': 'meri', 'root': 'meri', 'root_tokens': ['meri'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('xhus', [{'normalized_text': 'õhus', 'lemma': 'õhk', 'root': 'õhk', 'root_tokens': ['õhk'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}]),\n",
       "Span('vxi', [{'normalized_text': 'või', 'lemma': 'või', 'root': 'või', 'root_tokens': ['või'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('metsas', [{'normalized_text': 'metsas', 'lemma': 'mets', 'root': 'mets', 'root_tokens': ['mets'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Voilà !_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes about `normalized_text`:\n",
    "   * Dictionary's entry for a word may contain `normalized_text` value, but this is not mandatory. Note, however, that if  `normalized_text` is missing from the entry (and you are using complete overwriting), then by default, the value of `normalized_text` will be set to `None`;\n",
    "\n",
    "\n",
    "   * You can initialize `UserDictTagger` with the parameter `replace_missing_normalized_text_with_text=True`. After that, if a `normalized_text` is missing from the dictionary entry, then its value will be replaced with word's text. Note, however, that if word's text is a non-standard word form (such as _vajd_, _xhus_, _vxi_ in the previous example), then the outcome will be misleading (a normalized_text is actually the non-standard one). So, you should use this option only if all word texts in your dictionary correspond to standard / normalized words;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial overwriting\n",
    "\n",
    "If the existing analysis only needs partial corrections (e.g. only root is incorrect), you can pass a dictionary with specific corrections to the `add_word` method. Existing analyses of the word will then be merged with the new attributes from the dictionary -- attributes present in the user dictionary will be overwritten, and attributes not present in the dictionary will remain as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävask</td>\n",
       "      <td>igapää_vask</td>\n",
       "      <td>['igapää', 'vask']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('igapäävased', [{'normalized_text': 'igapäävased', 'lemma': 'igapäävask', 'root': 'igapää_vask', 'root_tokens': ['igapää', 'vask'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: word thad needs corrections in the root and partofspeech\n",
    "text = Text('igapäävased')\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new user dictionary\n",
    "userdict = UserDictTagger()\n",
    "# Correct only 'root' and 'partofspeech' of the word (leave other attributes as they are)\n",
    "userdict.add_word('igapäävased', { 'root': 'iga_päevane', 'partofspeech': 'A'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäevane</td>\n",
       "      <td>iga_päevane</td>\n",
       "      <td>['iga', 'päevane']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('igapäävased', [{'normalized_text': 'igapäävased', 'lemma': 'igapäevane', 'root': 'iga_päevane', 'root_tokens': ['iga', 'päevane'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections:\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum requirement for the dictionary of partial overwriting: it must specify at least one of the fields: `'root'`, `'ending'`, `'clitic'`, `'form'`, and `'partofspeech'`. Note: if `'root'` is provided, then `'partofspeech'` must also be provided (see below for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overwriting `'root'`, `'lemma'` and `'root_tokens'`\n",
    "\n",
    "Attributes `'root'` and `'lemma'` and `'root_tokens'` all record information about the morphological base form of the word, and its segmentation. \n",
    "If you need to change one of these attributes, you should update all in order to keep the data consistent. \n",
    "There is a systematic way how to do it.\n",
    "You should restrict your dictionary entries only to `'root'` and `'partofspeech'` (and `'ending'`, if required). Attributes `'lemma'` and `'root_tokens'` will then be automatically generated based on `'root'` and `'partofspeech'` (so, no need to manually provide entries for `'lemma'` and `'root_tokens'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abi_elu_ette_panek</td>\n",
       "      <td>['abi', 'elu', 'ette', 'panek']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('abieluettepanek', [{'normalized_text': 'abieluettepanek', 'lemma': 'abieluettepanek', 'root': 'abi_elu_ette_panek', 'root_tokens': ['abi', 'elu', 'ette', 'panek'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: compound word thad needs corrections in the root\n",
    "text = Text('abieluettepanek')\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new user dictionary with corrections to root and pos\n",
    "userdict = UserDictTagger()\n",
    "userdict.add_word('abieluettepanek', { 'root': 'abielu_ettepanek', 'partofspeech': 'S' } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abielu_ettepanek</td>\n",
       "      <td>['abielu', 'ettepanek']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('abieluettepanek', [{'normalized_text': 'abieluettepanek', 'lemma': 'abieluettepanek', 'root': 'abielu_ettepanek', 'root_tokens': ['abielu', 'ettepanek'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete overwriting\n",
    "\n",
    "If you pass a list of dictionaries to the method `add_word`, then all old anayses of the word will be replaced by the analyses in the user dictionary. Adding a list with a single dictionary means that the word is unambiguous, and multiple dictionaries represent different analysis variants of an ambiguous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>['vist']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>['onn']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>['rahul']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('vist', [{'normalized_text': 'vist', 'lemma': 'vist', 'root': 'vist', 'root_tokens': ['vist'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('onn', [{'normalized_text': 'onn', 'lemma': 'onn', 'root': 'onn', 'root_tokens': ['onn'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('rahul', [{'normalized_text': 'rahul', 'lemma': 'rahul', 'root': 'rahul', 'root_tokens': ['rahul'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: verb needs corrections, but the ambiguities should remain\n",
    "#          ( because it is not clear from the context, which form is correct )\n",
    "text = Text('vist onn rahul')\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new user dictionary with multiple analysis variants\n",
    "userdict = UserDictTagger()\n",
    "userdict.add_word('onn', [{'form': 'b', 'root': 'ole', 'ending':'0', 'partofspeech': 'V', 'clitic':''},\\\n",
    "                          {'form': 'vad', 'root': 'ole', 'ending':'0', 'partofspeech': 'V', 'clitic':''} ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>['vist']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>None</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>['rahul']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('vist', [{'normalized_text': 'vist', 'lemma': 'vist', 'root': 'vist', 'root_tokens': ['vist'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('onn', [{'normalized_text': None, 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': None, 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('rahul', [{'normalized_text': 'rahul', 'lemma': 'rahul', 'root': 'rahul', 'root_tokens': ['rahul'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum requirement for the dictionary used in complete overwriting: it must specify all the fields `'root'`, `'ending'`, `'clitic'`, `'form'`, and `'partofspeech'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some details\n",
    "\n",
    "#### About dictionary lookup\n",
    "\n",
    "Words that you add to `UserDictTagger` will be matched against `normalized_text` values of text's morphological analyses. \n",
    "If a morphological analysis has `normalized_text` equal to `None`, then the dictionary word will be matched against `text` of the morphological analysis. By default, the matching is case sensitive, but you can turn it off by setting `ignore_case=True` when initializing `UserDictTagger`.\n",
    "\n",
    "#### About matching and matching priorities\n",
    "\n",
    "If a match is found, and `UserDictTagger`'s entry for the word corresponds to a dictionary, then the _partial overwriting strategy_ will be applied: only those morphological analysis' attributes that are in the dictionary will overwritten, and all other attributes remain as they are.\n",
    "If matching word's entry is a list of dictionaries, the _complete overwriting strategy_ will be applied: all morphological analyses of the word will be replaced by analyses from the corresponding `UserDictTagger`'s entry.\n",
    "\n",
    "If some of word's morphological analyses obtain _partial overwriting_ matches, and some obtain _complete overwriting_ matches, then the final result will be complete overwriting according to the last complete overwriting match.\n",
    "In similar vein, if there is more than one morphological analysis that obtains a complete overwriting match, then the final result will be overwriting according to the last complete overwriting match (so, all matches previous to the last will be ignored).\n",
    "\n",
    "#### Browsing the content of dictionary\n",
    "\n",
    "You can use tagger's method `save_as_csv( None )` to get the full content of the user dictionary as a CSV formatted string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\troot\tending\tclitic\tform\tpartofspeech\n",
      "onn\tole\t0\t\tb\tV\n",
      "onn\tole\t0\t\tvad\tV\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "print( userdict.save_as_csv(None) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the section \"Saving analyses to CSV file\" below for details about the method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading analyses from CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of specifying analyses via method `add_word`, you can also use method `add_words_from_csv_file` to load analyses from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mxnel</td>\n",
       "      <td>mxnel</td>\n",
       "      <td>mxne</td>\n",
       "      <td>mxne</td>\n",
       "      <td>['mxne']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>['ka']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävask</td>\n",
       "      <td>igapää_vask</td>\n",
       "      <td>['igapää', 'vask']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljänd</td>\n",
       "      <td>kxnekeeleväljänd</td>\n",
       "      <td>['kxnekeeleväljänd']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljändi</td>\n",
       "      <td>kxnekeeleväljändi</td>\n",
       "      <td>['kxnekeeleväljändi']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljänt</td>\n",
       "      <td>kxnekeeleväljänt</td>\n",
       "      <td>['kxnekeeleväljänt']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sellged</td>\n",
       "      <td>sellged</td>\n",
       "      <td>sellge</td>\n",
       "      <td>sellge</td>\n",
       "      <td>['sellge']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>sellged</td>\n",
       "      <td>sellged</td>\n",
       "      <td>sellged</td>\n",
       "      <td>['sellged']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mxnel', [{'normalized_text': 'mxnel', 'lemma': 'mxne', 'root': 'mxne', 'root_tokens': ['mxne'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span('ka', [{'normalized_text': 'ka', 'lemma': 'ka', 'root': 'ka', 'root_tokens': ['ka'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('igapäävased', [{'normalized_text': 'igapäävased', 'lemma': 'igapäävask', 'root': 'igapää_vask', 'root_tokens': ['igapää', 'vask'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('kxnekeeleväljändid', [{'normalized_text': 'kxnekeeleväljändid', 'lemma': 'kxnekeeleväljänd', 'root': 'kxnekeeleväljänd', 'root_tokens': ['kxnekeeleväljänd'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'kxnekeeleväljändid', 'lemma': 'kxnekeeleväljändi', 'root': 'kxnekeeleväljändi', 'root_tokens': ['kxnekeeleväljändi'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'kxnekeeleväljändid', 'lemma': 'kxnekeeleväljänt', 'root': 'kxnekeeleväljänt', 'root_tokens': ['kxnekeeleväljänt'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('sellged', [{'normalized_text': 'sellged', 'lemma': 'sellge', 'root': 'sellge', 'root_tokens': ['sellge'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'sellged', 'lemma': 'sellged', 'root': 'sellged', 'root_tokens': ['sellged'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: a difficult-to-analyse sentence from the Internet language\n",
    "text = Text(\"mxnel ka igapäävased kxnekeeleväljändid sellged\")\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV file with correct analyses\n",
    "import tempfile\n",
    "fp = tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', suffix='.csv', delete=False)\n",
    "# Add header\n",
    "fp.write('text,form,root,ending,partofspeech,clitic\\n')\n",
    "# Add analyses\n",
    "fp.write('mxnel,sg ad,mõni,l,P,\\n')\n",
    "fp.write('igapäävased,pl n,iga_päevane,d,A,\\n')\n",
    "fp.write('kxnekeeleväljändid,pl n,kõne_keele_väljend,d,S,\\n')\n",
    "fp.write('sellged,pl n,selge,d,A,\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is required that the first line of the CSV file is the header, and uses the heading names `'root'`, `'ending'`, `'clitic'`, `'form'`, `'partofspeech'`, `'text'`. This is required to determine in which order the data has to be loaded from the file.\n",
    "\n",
    "Each line following the heading specifies a single analysis for a word. The word itself must be under the column `'text'`. Note that like in case of the _complete overwriting_, all the fields `'root'`, `'ending'`, `'clitic'`, `'form'` and `'partofspeech'` must be specified. You can also provide multiple lines describing a single word: these will be then considered as different analysis variants of an ambiguous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new user dictionary with the analyses loaded from the CSV file\n",
    "userdict = UserDictTagger()\n",
    "userdict.add_words_from_csv_file(fp.name, encoding='utf-8', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can pass optional parameters, such as `dialect` and `delimiter`, to the method `add_words_from_csv_file( filename )` in order to specify the formatting of the CSV file. Basically, you can use the same parameters as can be used with the method `csv.reader`: https://docs.python.org/3/library/csv.html#csv.reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mxnel</td>\n",
       "      <td>None</td>\n",
       "      <td>mõni</td>\n",
       "      <td>mõni</td>\n",
       "      <td>['mõni']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>['ka']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>None</td>\n",
       "      <td>igapäevane</td>\n",
       "      <td>iga_päevane</td>\n",
       "      <td>['iga', 'päevane']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>None</td>\n",
       "      <td>kõnekeeleväljend</td>\n",
       "      <td>kõne_keele_väljend</td>\n",
       "      <td>['kõne', 'keele', 'väljend']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sellged</td>\n",
       "      <td>None</td>\n",
       "      <td>selge</td>\n",
       "      <td>selge</td>\n",
       "      <td>['selge']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mxnel', [{'normalized_text': None, 'lemma': 'mõni', 'root': 'mõni', 'root_tokens': ['mõni'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'P'}]),\n",
       "Span('ka', [{'normalized_text': 'ka', 'lemma': 'ka', 'root': 'ka', 'root_tokens': ['ka'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('igapäävased', [{'normalized_text': None, 'lemma': 'igapäevane', 'root': 'iga_päevane', 'root_tokens': ['iga', 'päevane'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}]),\n",
       "Span('kxnekeeleväljändid', [{'normalized_text': None, 'lemma': 'kõnekeeleväljend', 'root': 'kõne_keele_väljend', 'root_tokens': ['kõne', 'keele', 'väljend'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('sellged', [{'normalized_text': None, 'lemma': 'selge', 'root': 'selge', 'root_tokens': ['selge'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up: remove temporary file\n",
    "import os\n",
    "os.remove(fp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving analyses to CSV file\n",
    "\n",
    "Method `save_as_csv( filename )` can be used for saving the content of the user dictionary to a CSV format file. The data is saved in a way that it can be loaded with the method `add_words_from_csv_file( filename )`. \n",
    "\n",
    "Note 1: you can also pass optional parameters, such as `dialect` and `delimiter`, to the `save_as_csv( filename )` in order to change the formatting of the CSV. Basically, you can use the same parameters as can be used with the method `csv.writer`: https://docs.python.org/3/library/csv.html#csv.writer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 2: if you use `None` in place of _filename_, then the method constructs and returns a CSV formatted string instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\troot\tending\tclitic\tform\tpartofspeech\n",
      "igapäävased\tiga_päevane\td\t\tpl n\tA\n",
      "kxnekeeleväljändid\tkõne_keele_väljend\td\t\tpl n\tS\n",
      "mxnel\tmõni\tl\t\tsg ad\tP\n",
      "sellged\tselge\td\t\tpl n\tA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "print( userdict.save_as_csv( None ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 3: if the dictionary contains partial overwriting entries, then the output CSV will have `'----------'` in places of attribute values that were not described in the (partial overwriting) dictionary."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
