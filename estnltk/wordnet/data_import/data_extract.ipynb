{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../source_data/estwn-et-2.3.2.xml\", encoding=\"UTF-8\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding all lexical entries by their tag\n",
    "entries = soup.find_all('lexicalentry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting relevant information from all Wordnet entries from the XML-file\n",
    "wn_entries = []\n",
    "\n",
    "for entry in entries:\n",
    "    lemma_info = entry.find('lemma')\n",
    "    pos = lemma_info.get('partofspeech')\n",
    "    lemma = lemma_info.get('writtenform')\n",
    "    for sense in entry.find_all('sense'):\n",
    "        sense_id = sense.get('id')\n",
    "        estwn_id = sense.get('synset')\n",
    "        sense = re.sub('[^0-9]', '', sense_id.split('-')[-1])\n",
    "        wn_entries.append((lemma, pos, sense, sense_id, estwn_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding all synset objects by the synset tag\n",
    "synsets = soup.find_all('synset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the name (main phrase of the synset) for synsets, most of them can be found from the definition of the synset\n",
    "sourcesenses = {}\n",
    "\n",
    "for s in synsets:\n",
    "    d = s.find('definition')\n",
    "    if d is not None and d.get('sourcesense') not in sourcesenses:\n",
    "        if d.get('sourcesense') is not None:\n",
    "            sourcesenses[s.get('id')] = d.get('sourcesense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of tuples where each tuple contains relevant information about one lexical entry\n",
    "db_entries = []\n",
    "\n",
    "for entry in wn_entries:\n",
    "    #Most of the names were found previously, but for some synsets, they couldn't be obtained.\n",
    "    #In those cases, the name of the first lexical entry of said synset is used as the name\n",
    "    if entry[-1] not in sourcesenses:\n",
    "        sourcesenses[entry[-1]] = entry[-2]\n",
    "    sourcesense = sourcesenses[entry[-1]]\n",
    "    if sourcesense == entry[3]:\n",
    "        #id is obtained from the estwn_id from the XML-file by removing all non-numeric characters from the string\n",
    "        db_entries.append((re.sub(\"[^0-9]\", \"\", entry[-1]), entry[0], entry[1], entry[2], sourcesense, entry[4], 1))\n",
    "    else:\n",
    "        db_entries.append((re.sub(\"[^0-9]\", \"\", entry[-1]), entry[0], entry[1], entry[2], sourcesense, entry[4], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of tuples (of synset relations) where each tuple contains the start vertex, end vertex and specified relation.\n",
    "#Start and end vertex of each relation are numeric id's of said synsets.\n",
    "db_relations = []\n",
    "\n",
    "for synset in synsets:\n",
    "    synset_id = re.sub(\"[^0-9]\", \"\", synset.get('id'))\n",
    "    relations = synset.find_all('synsetrelation')\n",
    "    for relation in relations:\n",
    "        db_relations.append((re.sub(\"[^0-9]\", \"\", relation.get('target')), synset_id, relation.get('reltype')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of tuples where each tuple consists of synset name and its definition\n",
    "db_definitions = []\n",
    "\n",
    "for synset in synsets:\n",
    "    definitions = synset.find_all('definition')\n",
    "    #if len(synset.find_all('definition')) > 1:\n",
    "    #    print(definitions)\n",
    "    #    print(set([str(d.find(text=True)) for d in definitions]))\n",
    "    #    print()\n",
    "    if definitions is not None:\n",
    "        for definition in definitions:\n",
    "            sourcesense = definition.get(\"sourcesense\")\n",
    "            if sourcesense is None:\n",
    "                db_definitions.append((sourcesenses[synset.get('id')], definition.find(text=True)))\n",
    "            else:\n",
    "                db_definitions.append((sourcesense, definition.find(text=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses = soup.find_all('sense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of tuples where each tuple consists of synset sense (literal) and an example for it\n",
    "db_examples = []\n",
    "\n",
    "for sense in senses:\n",
    "    examples = sense.find_all('example')\n",
    "    if examples is not None:\n",
    "        for example in examples:\n",
    "            db_examples.append((sense.get(\"id\"), example.find(text=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(file_path, db_name, create_table, insert, values):\n",
    "    conn = sqlite3.connect(file_path)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(create_table)\n",
    "    with conn:\n",
    "        cur.execute(\"DELETE FROM {};\".format(db_name)) #if database exists, deletes all values so there wouldn't be duplicates\n",
    "        cur.executemany(insert, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the 'Wordnet entries' database\n",
    "wn_entry_db = \"..//data//estwn-et-2.3.2//wordnet_entry.db\"\n",
    "wn_entry_name = \"wordnet_entry\"\n",
    "wn_entry_create = \"CREATE TABLE IF NOT EXISTS wordnet_entry(id INT, literal TEXT, pos TEXT, sense INT, synset_name TEXT, estwn_id TEXT, is_name INT)\"\n",
    "wn_entry_insert = \"insert into wordnet_entry(id, literal, pos, sense, synset_name, estwn_id, is_name) values (?,?,?,?,?,?,?)\"\n",
    "create_database(wn_entry_db, wn_entry_name, wn_entry_create, wn_entry_insert, db_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the 'Wordnet relations' database\n",
    "wn_relation_db = \"..//data//estwn-et-2.3.2//wordnet_relation.db\"\n",
    "wn_relation_name = \"wordnet_relation\"\n",
    "wn_relation_create = \"CREATE TABLE IF NOT EXISTS wordnet_relation(start_vertex INT, end_vertex INT, relation TEXT)\"\n",
    "wn_relation_insert = \"insert into wordnet_relation(start_vertex, end_vertex, relation) values (?,?,?)\"\n",
    "create_database(wn_relation_db, wn_relation_name, wn_relation_create, wn_relation_insert, db_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating the 'Wordnet definitions' database\n",
    "wn_definitions_db = \"..//data//estwn-et-2.3.2//wordnet_definition.db\"\n",
    "wn_definitions_name = \"wordnet_definition\"\n",
    "wn_definitions_create = \"CREATE TABLE IF NOT EXISTS wordnet_definition(synset_name TEXT, definition TEXT)\"\n",
    "wn_definitions_insert = \"insert into wordnet_definition(synset_name, definition) values (?,?)\"\n",
    "create_database(wn_definitions_db, wn_definitions_name, wn_definitions_create, wn_definitions_insert, db_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the 'Wordnet examples' database\n",
    "wn_examples_db = \"..//data//estwn-et-2.3.2//wordnet_example.db\"\n",
    "wn_examples_name = \"wordnet_example\"\n",
    "wn_examples_create = \"CREATE TABLE IF NOT EXISTS wordnet_example(synset_name TEXT, example TEXT)\"\n",
    "wn_examples_insert = \"insert into wordnet_example(synset_name, example) values (?,?)\"\n",
    "create_database(wn_examples_db, wn_examples_name, wn_examples_create, wn_examples_insert, db_examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
